{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wrapped-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surprised-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cat(y, num_cats):\n",
    "    res = []\n",
    "    for i in range(y.shape[0]):\n",
    "        label = [0]*num_cats\n",
    "        label[y[i]] = 1\n",
    "        res.append(label)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "different-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    num_correct = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        num_correct += y_pred[i].argmax() == y[i].argmax()\n",
    "    return num_correct / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-curtis",
   "metadata": {},
   "source": [
    "# Load and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greater-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddata_train = pd.read_csv('Data/sign_mnist_train.csv')\n",
    "data_train = pddata_train.values\n",
    "data_train_X = data_train[:,1:]\n",
    "data_train_y = data_train[:,:1].reshape(-1) # turn to 1d\n",
    "data_train_y = to_cat(data_train_y, 26)\n",
    "\n",
    "test_size = 0.1\n",
    "test_ind = int(test_size*data_train_X.shape[0])\n",
    "data_train_X, data_val_X, data_train_y, data_val_y = data_train_X[test_ind:], data_train_X[:test_ind],data_train_y[test_ind:], data_train_y[:test_ind]\n",
    "\n",
    "\n",
    "pddata_test = pd.read_csv('Data/sign_mnist_test.csv')\n",
    "data_test = pddata_test.values\n",
    "data_test_X = data_test[:, 1:]\n",
    "data_test_y = data_test[:, :1].reshape(-1) # turn to 1d\n",
    "data_test_y = to_cat(data_test_y, 26)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaled_train_X = scaler.fit_transform(data_train_X)\n",
    "# scaled_test_X = scaler.transform(data_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rural-restriction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24710 training samples\n",
      "There are 7172 training samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {data_train_X.shape[0]} training samples\")\n",
    "print(f\"There are {data_test_X.shape[0]} training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-celebration",
   "metadata": {},
   "source": [
    "# Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "russian-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dnn(num_input, layers, activations, dropouts, regularizations, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(num_input,)))\n",
    "    for num_nodes, act, dr, reg in zip(layers, activations, dropouts, regularizations):\n",
    "        model.add(Dense(num_nodes, activation=act, kernel_regularizer=reg))\n",
    "        if dr != 0:\n",
    "            model.add(Dropout(dr))\n",
    "            \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-overhead",
   "metadata": {},
   "source": [
    "# Testing Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "successful-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = [26]\n",
    "# activations = ['softmax']\n",
    "# dropouts=[0, 0, 0, 0]\n",
    "# optimizer=Adam(0.01)\n",
    "# regularizations = [\n",
    "#     l2(0.01)\n",
    "# ]\n",
    "# epochs=200\n",
    "# batch_size=256\n",
    "\n",
    "# early_stop = EarlyStopping(\n",
    "#     monitor=\"loss\",\n",
    "#     min_delta=0,\n",
    "#     patience=10,\n",
    "#     verbose=0,\n",
    "#     mode=\"auto\",\n",
    "#     baseline=None,\n",
    "#     restore_best_weights=True,\n",
    "# )\n",
    "\n",
    "# model = create_dnn(data_train_X[0].shape[0], layers, activations, dropouts, regularizations, optimizer)\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.fit(data_train_X, data_train_y, validation_data=(data_val_X, data_val_y), epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vietnamese-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(data_test_X, data_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-restriction",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "overall-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddata_train = pd.read_csv('Data/sign_mnist_train.csv')\n",
    "data_train = pddata_train.values\n",
    "data_train_X = data_train[:,1:]\n",
    "data_train_X = data_train_X\n",
    "data_train_y = data_train[:,:1].reshape(-1) # turn to 1d\n",
    "data_train_y = to_cat(data_train_y, 26)\n",
    "\n",
    "test_size = 0.1\n",
    "test_ind = int(test_size*data_train_X.shape[0])\n",
    "data_train_X, data_val_X, data_train_y, data_val_y = data_train_X[test_ind:], data_train_X[:test_ind],data_train_y[test_ind:], data_train_y[:test_ind]\n",
    "\n",
    "\n",
    "pddata_test = pd.read_csv('Data/sign_mnist_test.csv')\n",
    "data_test = pddata_test.values\n",
    "data_test_X = data_test[:, 1:]\n",
    "data_test_X = data_test_X.reshape((data_test_X.shape[0], 28,28,1))\n",
    "data_test_y = data_test[:, :1].reshape(-1) # turn to 1d\n",
    "data_test_y = to_cat(data_test_y, 26)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaled_train_X = scaler.fit_transform(data_train_X)\n",
    "# scaled_test_X = scaler.transform(data_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "disabled-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape, optimizer, regularizer):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv2D(8, 3, activation='selu', padding='same'))\n",
    "    model.add(MaxPooling2D(2))\n",
    "    model.add(Conv2D(4, 2, activation='selu', padding='same'))\n",
    "    model.add(MaxPooling2D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(26, activation='softmax', kernel_regularizer=regularizer))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "billion-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(lr, batch_size, epochs, reg):\n",
    "    model = create_cnn((28, 28,1), Adam(lr), reg)\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"loss\",\n",
    "        min_delta=0,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    model.fit(data_train_X, data_train_y, batch_size=batch_size, epochs=epochs, callbacks=[early_stop], verbose=0)\n",
    "    \n",
    "    results = model.evaluate(data_test_X, data_test_y)\n",
    "    return results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-rebate",
   "metadata": {},
   "source": [
    "# Testing Different Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expanded-creature",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7172/7172 [==============================] - 0s 57us/sample - loss: 0.4088 - accuracy: 0.8896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-83f0a2f19bf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-55c1855f7036>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(lr, batch_size, epochs, reg)\u001b[0m\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_test_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = np.logspace(-3, -0.5, 11)\n",
    "acc = []\n",
    "for l in lr:\n",
    "    acc.append(run_model(l, 256, 200, l2(0)))\n",
    "    \n",
    "plt.plot(acc)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy vs Learning Rate')\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)\n",
    "plt.savefig('Figures\\\\CNN test vs lambda l1.jpg', dpi=500)\n",
    "plt.plot()\n",
    "\n",
    "pd.DataFrame([lr, acc], index=['learning rate', 'accuracy']).transpose().to_csv('./Figures/CNN lr vs accuracy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-collective",
   "metadata": {},
   "source": [
    "# Testing Different Learning Batch Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "peaceful-fifteen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7172/7172 [==============================] - 1s 79us/sample - loss: 0.5407 - accuracy: 0.8164\n",
      "7172/7172 [==============================] - 0s 62us/sample - loss: 0.5257 - accuracy: 0.8302\n",
      "7172/7172 [==============================] - 0s 60us/sample - loss: 0.4844 - accuracy: 0.8618\n",
      "7172/7172 [==============================] - 1s 74us/sample - loss: 0.4335 - accuracy: 0.8726\n",
      "7172/7172 [==============================] - 1s 70us/sample - loss: 0.4218 - accuracy: 0.8851\n",
      "7172/7172 [==============================] - 1s 70us/sample - loss: 0.4903 - accuracy: 0.8855\n",
      "7172/7172 [==============================] - 0s 69us/sample - loss: 0.4192 - accuracy: 0.8996\n",
      "7172/7172 [==============================] - 0s 56us/sample - loss: 0.4665 - accuracy: 0.8682\n",
      "7172/7172 [==============================] - 0s 66us/sample - loss: 0.7515 - accuracy: 0.8021\n"
     ]
    }
   ],
   "source": [
    "batches = [4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "acc = []\n",
    "for b in batches:\n",
    "    acc.append(run_model(0.002, b, 200, l2(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-learning",
   "metadata": {},
   "source": [
    "# Testing Different Lambdas for l1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "lonely-business",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7172/7172 [==============================] - 0s 58us/sample - loss: 0.4093 - accuracy: 0.8721\n",
      "7172/7172 [==============================] - 0s 60us/sample - loss: 0.5600 - accuracy: 0.8744\n",
      "7172/7172 [==============================] - 0s 61us/sample - loss: 0.6889 - accuracy: 0.8560\n",
      "7172/7172 [==============================] - 0s 62us/sample - loss: 0.6078 - accuracy: 0.8939\n",
      "7172/7172 [==============================] - 1s 72us/sample - loss: 0.9017 - accuracy: 0.8689\n",
      "7172/7172 [==============================] - 0s 59us/sample - loss: 0.9242 - accuracy: 0.8688\n",
      "7172/7172 [==============================] - 1s 70us/sample - loss: 1.1373 - accuracy: 0.8186\n",
      "7172/7172 [==============================] - 0s 68us/sample - loss: 1.4465 - accuracy: 0.7751\n",
      "7172/7172 [==============================] - 0s 62us/sample - loss: 1.5541 - accuracy: 0.7812\n",
      "7172/7172 [==============================] - 0s 67us/sample - loss: 1.9996 - accuracy: 0.7563\n",
      "7172/7172 [==============================] - 0s 64us/sample - loss: 2.3046 - accuracy: 0.6893\n",
      "7172/7172 [==============================] - 0s 69us/sample - loss: 3.6140 - accuracy: 0.0735\n"
     ]
    }
   ],
   "source": [
    "lamb = [0]+list(np.logspace(-3, -0.5, 11))\n",
    "acc = []\n",
    "for l in lamb:\n",
    "    acc.append(run_model(0.002, 256, 200, l1(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-surfing",
   "metadata": {},
   "source": [
    "# Testing Different Lambdas for l2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = [0]+list(np.logspace(-3, -0.5, 11))\n",
    "acc = []\n",
    "for l in lamb:\n",
    "    acc.append(run_model(0.002, 256, 200, l1(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bulgarian-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([lamb, acc]).transpose().to_csv('Figures\\\\CNN test vs lambda l1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-radar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
